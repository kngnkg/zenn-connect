---
title: "sqldefã§RDSã‚’ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹Lambdaé–¢æ•°ã‚’ä½œæˆã™ã‚‹"
emoji: "ğŸ£"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["åˆæŠ•ç¨¿", "Lambda", "Terraform", "Go","sqldef"]
published: true
---

ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®DBã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯[sqldef](https://github.com/k0kubun/sqldef)ã¨ã„ã†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã¨ã¦ã‚‚ä¾¿åˆ©ãªãƒ„ãƒ¼ãƒ«ãªã®ã§ã€AWSç’°å¢ƒã§ã‚‚ä½¿ç”¨ã—ãŸã„ã§ã™ã€‚

ãŸã ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚µãƒ–ãƒãƒƒãƒˆã®RDSã‚’ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹å ´åˆã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚è¸ã¿å°çµŒç”±ã§å®Ÿè¡Œã™ã‚‹ã®ã¯é¢å€’ã§ã™ã—ã€è¸ã¿å°ã¨ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å¸¸æ™‚ç«‹ã¦ã¦ãŠãã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã¾ã™ã€‚

ã“ã‚Œã‚‰ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ä»Šå›ã¯CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã¿ã€ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•åŒ–ã™ã‚‹Lambdaé–¢æ•°ã®ä½œæˆã«å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ãŸã€‚

ãƒªãƒã‚¸ãƒˆãƒªã¯ä»¥ä¸‹ã«ã‚ã‚Šã¾ã™ã€‚
https://github.com/kngnkg/tunetrail/tree/main/migration

## `sqldef`ã«ã¤ã„ã¦

[sqldef](https://github.com/k0kubun/sqldef)ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®å®šç¾©ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©ã—ãŸ`.sql`ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¿…è¦ãªDDLã‚’è‡ªå‹•ã§ç”Ÿæˆã—å®Ÿè¡Œã—ã¦ãã‚Œã¾ã™ã€‚

`sqldef`ã¯CLIãƒ„ãƒ¼ãƒ«ã§ã™ãŒã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦Goã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚

## AWS Lambdaé–¢æ•°

Terraformã§ä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚IAMãƒ­ãƒ¼ãƒ«ãªã©ã¯å‰²æ„›ã—ã¾ã™ã€‚

- Lambdaé–¢æ•°
- S3ãƒã‚±ãƒƒãƒˆ (`.sql`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãŸã‚)
- VPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (Lambdaé–¢æ•°ã‹ã‚‰S3ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚)
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ— (VPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨)

```hcl
resource "aws_lambda_function" "migration" {
  function_name = "migration_lambda"
  image_uri     = "${aws_ecr_repository.migration.repository_url}:${var.migration_image_tag}" # ECRã®ãƒªãƒã‚¸ãƒˆãƒªURL
  role          = aws_iam_role.lambda_exec.arn
  timeout = 60
  memory_size  = 128
  package_type = "Image"
  vpc_config {
    subnet_ids         = [aws_subnet.private1.id, aws_subnet.private2.id]
    security_group_ids = [aws_security_group.migration_sg.id]
  }
  environment {
    variables = {
      S3_BUCKET   = "${aws_s3_bucket.schema.bucket}"
      DB_HOST     = "host"
      DB_PORT     = 5432
      DB_USER     = "user"
      DB_PASSWORD = "password"
      DB_NAME     = "db-name"
    }
  }
}

resource "aws_s3_bucket" "schema" {
  bucket = "bucket-name"
}
resource "aws_s3_bucket_versioning" "schema_versioning" {
  bucket = aws_s3_bucket.schema.id
  versioning_configuration {
    mfa_delete = "Disabled"
    status     = "Enabled"
  }
}

resource "aws_vpc_endpoint" "s3" {
  count             = 1
  vpc_id            = aws_vpc.main.id
  service_name      = "com.amazonaws.ap-northeast-1.s3"
  vpc_endpoint_type = "Gateway"
  route_table_ids   = [aws_route_table.private.id]
}

resource "aws_security_group" "migration_sg" {
  name        = "migration_sg"
  description = "Security Group for migration"
  vpc_id      = aws_vpc.main.id
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["10.0.0.0/16"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

### å®Ÿè£…

[Go](https://go.dev/#)ã§å®Ÿè£…ã—ã¾ã—ãŸã€‚S3ã«ä¿å­˜ã—ãŸ`.sql`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€`sqldef`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

è©³ç´°ã¯[ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/kngnkg/tunetrail/tree/main/migration)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```go
type Event struct {
	Items []string `json:"items"`
}

type Response struct {
	Result string `json:"result"`
}

func getSchemaFilesFromS3(ctx context.Context, region string, S3Bucket string, objectKeys []string) ([]string, error) {
	sess, err := session.NewSession(&aws.Config{
		Region: aws.String(region),
	})
	if err != nil {
		return nil, err
	}

	s3dl := s3downloader.New(sess, S3Bucket)
	var files []string
	for _, objectKey := range objectKeys {
		file, err := s3dl.Download(ctx, objectKey)
		if err != nil {
			return nil, err
		}
		files = append(files, file.Name())
	}
	return files, nil
}

func migrate(ctx context.Context, cfg *config.Config, files []string) error {
	desiredFiles := sqldef.ParseFiles(files)
	desiredDDLs, err := sqldef.ReadFiles(desiredFiles)
	if err != nil {
		return err
	}

	options := &sqldef.Options{
		DesiredDDLs: desiredDDLs,
		DryRun:      cfg.DryRun,
	}

	dbCfg := database.Config{
		DbName:   cfg.DBName,
		User:     cfg.DBUser,
		Password: cfg.DBPassword,
		Host:     cfg.DBHost,
		Port:     cfg.DBPort,
	}

	db, err := postgres.NewDatabase(dbCfg)
	if err != nil {
		return err
	}

	sqlParser := postgres.NewParser()

	if cfg.Env == "dev" {
		os.Setenv("PGSSLMODE", "disable")
	}
	sqldef.Run(schema.GeneratorModePostgres, db, sqlParser, options)
	return nil
}

func handleRequest(ctx context.Context, event Event) (Response, error) {
	cfg, err := config.New()
	if err != nil {
		log.Fatalf("Error loading config: %v", err)
	}

	files, err := getSchemaFilesFromS3(ctx, cfg.AWSRegion, cfg.S3Bucket, event.Items)
	if err != nil {
		log.Fatalf("Error getting schema file: %v", err)
	}

	if err := migrate(ctx, cfg, files); err != nil {
		log.Fatalf("Error migration: %v", err)
	}

	return Response{Result: "Success"}, nil
}

func main() {
	lambda.Start(handleRequest)
}

```

### Dockerfile

ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã—ã¾ã™ã€‚`Dockerfile`ã®è¨˜è¿°ã«ã¤ã„ã¦ã¯[è©³è§£Goè¨€èªWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™º](https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3Go%E8%A8%80%E8%AA%9EWeb%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E9%96%8B%E7%99%BA-%E6%B8%85%E6%B0%B4-%E9%99%BD%E4%B8%80%E9%83%8E/dp/4863543727)ã‚’å‚è€ƒã«ã—ã¾ã—ãŸã€‚

```Dockerfile
FROM golang:1.20.3-bullseye as deploy-builder

WORKDIR /app

COPY go.mod go.sum ./
RUN go mod download

COPY . .

RUN go build -trimpath -ldflags "-w -s" -o app

# ---------------------------------------------------

FROM debian:bullseye-slim as deploy

COPY --from=deploy-builder /app/app .

# S3ã¨HTTPSæ¥ç¶šã™ã‚‹ãŸã‚ã«ca-certificatesã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™
RUN apt-get update && \
    apt-get install -y --no-install-recommends ca-certificates && \
    rm -rf /var/lib/apt/lists/*

CMD ["./app"]

```

## ä½¿ã„æ–¹

ã‚¹ã‚­ãƒ¼ãƒãŒå®šç¾©ã•ã‚ŒãŸ`.sql`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ã€ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’Lambdaé–¢æ•°ã«æ¸¡ã™ã“ã¨ã§å®Ÿè¡Œã§ãã¾ã™ã€‚

GitHub Actionsã§ä½¿ç”¨ã™ã‚‹ä¾‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

```yml
    - name: Upload schema file
      run: |
        set -e
        aws s3 cp /path/to/schema.sql s3://${{ secrets.S3_BUCKET }}/schema.sql
    - name: Invoke Lambda function
      run: |
        set -e
        output=$(aws lambda invoke --function-name your_lambda_function --payload $(echo '{ "items": ["schema.sql"] }' | base64) response.json)
        if echo "$output" | grep -q "FunctionError"; then
          echo "Lambda function execution failed."
          echo "$output"
          exit 1
        fi
```

## ã¾ã¨ã‚

AWSç’°å¢ƒã§ã‚‚`sqldef`ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã§ãã¾ã—ãŸã€‚CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã€é–‹ç™ºè€…ã¯ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ„è­˜ã™ã‚‹ã“ã¨ãªãé–‹ç™ºã‚’é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## å‚è€ƒè³‡æ–™

https://k0kubun.hatenablog.com/entry/2018/08/25/114455

https://qiita.com/crossroad0201/items/98f8935b4da1118566a4

https://zenn.dev/tchssk/articles/27a6c6c8aba40d
