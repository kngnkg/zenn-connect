---
title: "sqldefでRDSをマイグレーションするLambda関数を作成する"
emoji: "🐣"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["初投稿", "Lambda", "Terraform", "Go","sqldef"]
published: true
---

ローカル環境でのDBのマイグレーションは[sqldef](https://github.com/k0kubun/sqldef)というツールを使用しています。とても便利なツールなので、AWS環境でも使用したいです。

ただし、プライベートサブネットのRDSをマイグレーションする場合はいくつかの課題があります。踏み台経由で実行するのは面倒ですし、踏み台となるインスタンスを常時立てておくのはコストがかかります。

これらの問題を解決するため、今回はCI/CDパイプラインに組み込み、マイグレーションを自動化するLambda関数の作成に取り組んでみました。

リポジトリは以下にあります。
https://github.com/kngnkg/tunetrail/tree/main/migration

## `sqldef`について

[sqldef](https://github.com/k0kubun/sqldef)は、データベーススキーマの定義を管理するためのコマンドラインツールです。スキーマを定義した`.sql`ファイルから必要なDDLを自動で生成し実行してくれます。

`sqldef`はCLIツールですが、ライブラリとしてGoのプログラムから直接呼び出すことも可能です。

## AWS Lambda関数

Terraformで以下のリソースを作成します。IAMロールなどは割愛します。

- Lambda関数
- S3バケット (`.sql`ファイルを保存するため)
- VPCエンドポイント (Lambda関数からS3にアクセスするため)
- セキュリティグループ (VPCエンドポイント用)

```hcl
resource "aws_lambda_function" "migration" {
  function_name = "migration_lambda"
  image_uri     = "${aws_ecr_repository.migration.repository_url}:${var.migration_image_tag}" # ECRのリポジトリURL
  role          = aws_iam_role.lambda_exec.arn
  timeout = 60
  memory_size  = 128
  package_type = "Image"
  vpc_config {
    subnet_ids         = [aws_subnet.private1.id, aws_subnet.private2.id]
    security_group_ids = [aws_security_group.migration_sg.id]
  }
  environment {
    variables = {
      S3_BUCKET   = "${aws_s3_bucket.schema.bucket}"
      DB_HOST     = "host"
      DB_PORT     = 5432
      DB_USER     = "user"
      DB_PASSWORD = "password"
      DB_NAME     = "db-name"
    }
  }
}

resource "aws_s3_bucket" "schema" {
  bucket = "bucket-name"
}
resource "aws_s3_bucket_versioning" "schema_versioning" {
  bucket = aws_s3_bucket.schema.id
  versioning_configuration {
    mfa_delete = "Disabled"
    status     = "Enabled"
  }
}

resource "aws_vpc_endpoint" "s3" {
  count             = 1
  vpc_id            = aws_vpc.main.id
  service_name      = "com.amazonaws.ap-northeast-1.s3"
  vpc_endpoint_type = "Gateway"
  route_table_ids   = [aws_route_table.private.id]
}

resource "aws_security_group" "migration_sg" {
  name        = "migration_sg"
  description = "Security Group for migration"
  vpc_id      = aws_vpc.main.id
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["10.0.0.0/16"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

### 実装

[Go](https://go.dev/#)で実装しました。S3に保存した`.sql`ファイルを読み込んで、`sqldef`パッケージでマイグレーションを実行します。

詳細は[リポジトリ](https://github.com/kngnkg/tunetrail/tree/main/migration)を参照してください。

```go
type Event struct {
	Items []string `json:"items"`
}

type Response struct {
	Result string `json:"result"`
}

func getSchemaFilesFromS3(ctx context.Context, region string, S3Bucket string, objectKeys []string) ([]string, error) {
	sess, err := session.NewSession(&aws.Config{
		Region: aws.String(region),
	})
	if err != nil {
		return nil, err
	}

	s3dl := s3downloader.New(sess, S3Bucket)
	var files []string
	for _, objectKey := range objectKeys {
		file, err := s3dl.Download(ctx, objectKey)
		if err != nil {
			return nil, err
		}
		files = append(files, file.Name())
	}
	return files, nil
}

func migrate(ctx context.Context, cfg *config.Config, files []string) error {
	desiredFiles := sqldef.ParseFiles(files)
	desiredDDLs, err := sqldef.ReadFiles(desiredFiles)
	if err != nil {
		return err
	}

	options := &sqldef.Options{
		DesiredDDLs: desiredDDLs,
		DryRun:      cfg.DryRun,
	}

	dbCfg := database.Config{
		DbName:   cfg.DBName,
		User:     cfg.DBUser,
		Password: cfg.DBPassword,
		Host:     cfg.DBHost,
		Port:     cfg.DBPort,
	}

	db, err := postgres.NewDatabase(dbCfg)
	if err != nil {
		return err
	}

	sqlParser := postgres.NewParser()

	if cfg.Env == "dev" {
		os.Setenv("PGSSLMODE", "disable")
	}
	sqldef.Run(schema.GeneratorModePostgres, db, sqlParser, options)
	return nil
}

func handleRequest(ctx context.Context, event Event) (Response, error) {
	cfg, err := config.New()
	if err != nil {
		log.Fatalf("Error loading config: %v", err)
	}

	files, err := getSchemaFilesFromS3(ctx, cfg.AWSRegion, cfg.S3Bucket, event.Items)
	if err != nil {
		log.Fatalf("Error getting schema file: %v", err)
	}

	if err := migrate(ctx, cfg, files); err != nil {
		log.Fatalf("Error migration: %v", err)
	}

	return Response{Result: "Success"}, nil
}

func main() {
	lambda.Start(handleRequest)
}

```

### Dockerfile

マルチステージビルドでイメージサイズを削減します。`Dockerfile`の記述については[詳解Go言語Webアプリケーション開発](https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3Go%E8%A8%80%E8%AA%9EWeb%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E9%96%8B%E7%99%BA-%E6%B8%85%E6%B0%B4-%E9%99%BD%E4%B8%80%E9%83%8E/dp/4863543727)を参考にしました。

```Dockerfile
FROM golang:1.20.3-bullseye as deploy-builder

WORKDIR /app

COPY go.mod go.sum ./
RUN go mod download

COPY . .

RUN go build -trimpath -ldflags "-w -s" -o app

# ---------------------------------------------------

FROM debian:bullseye-slim as deploy

COPY --from=deploy-builder /app/app .

# S3とHTTPS接続するためにca-certificatesをインストールします
RUN apt-get update && \
    apt-get install -y --no-install-recommends ca-certificates && \
    rm -rf /var/lib/apt/lists/*

CMD ["./app"]

```

## 使い方

スキーマが定義された`.sql`ファイルをS3にアップロードしてから、そのオブジェクトキーをLambda関数に渡すことで実行できます。

GitHub Actionsで使用する例を紹介します。

```yml
    - name: Upload schema file
      run: |
        set -e
        aws s3 cp /path/to/schema.sql s3://${{ secrets.S3_BUCKET }}/schema.sql
    - name: Invoke Lambda function
      run: |
        set -e
        output=$(aws lambda invoke --function-name your_lambda_function --payload $(echo '{ "items": ["schema.sql"] }' | base64) response.json)
        if echo "$output" | grep -q "FunctionError"; then
          echo "Lambda function execution failed."
          echo "$output"
          exit 1
        fi
```

## まとめ

AWS環境でも`sqldef`を使用してマイグレーションを実行できました。CI/CDパイプラインを構築することで、開発者はマイグレーションを意識することなく開発を進めることができます。

## 参考資料

https://k0kubun.hatenablog.com/entry/2018/08/25/114455

https://qiita.com/crossroad0201/items/98f8935b4da1118566a4

https://zenn.dev/tchssk/articles/27a6c6c8aba40d
